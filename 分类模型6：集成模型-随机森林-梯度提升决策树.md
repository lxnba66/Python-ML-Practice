
***集成学习大体上分为两种：一种是利用相同的训练数据同时搭建多个独立的分类模型，然后通过投票的方式，以少数服从多数的原则做出最终的分类决策。如随即森林分类器。与决策树不同的是，随机森林分类器在构建的过程中，每一棵决策树都会放弃这一固定的排序算法，转而随机选取特征。  
       另一种则是按照一定次序搭建多个分类模型。这些模型之间彼此存在依赖关系。一般而言，每一个后续模型的加入都需要对现有集成模型的综合性能有所贡献，进而不断提升更新过后的集成模型的性能，并最终期望借助整合多个分类能力较弱的分类器，搭建出具有更强分类能力的模型。比较有代表性的当属梯度提升决策树。与构建随机森林分类器模型不同，这里每一棵决策树在生成的过程中都会尽可能降低整体集成模型在训练集上的拟合误差。***

### 代码32：集成模型对TITANIC乘客生还预测


```python
import pandas as pd
titanic = pd.read_csv("http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt")
X = titanic[['pclass', 'age', 'sex']]
y = titanic['survived']
```


```python
# 均值填补缺失值
X['age'].fillna(X['age'].mean(), inplace = True)
# 数据分割
from sklearn.cross_validation import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 33)
```

    C:\ProgramData\Anaconda3\lib\site-packages\pandas\core\generic.py:4355: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame
    
    See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
      self._update_inplace(new_data)
    C:\ProgramData\Anaconda3\lib\site-packages\sklearn\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
      "This module will be removed in 0.20.", DeprecationWarning)
    


```python
# 对类别型特征进行转化，成为特征向量
from sklearn.feature_extraction import DictVectorizer
vec = DictVectorizer(sparse = False)
X_train = vec.fit_transform(X_train.to_dict(orient = 'record'))
X_test = vec.transform(X_test.to_dict(orient = 'record'))
```


```python
#  使用单一决策树进行模型训练以及预测分析
from sklearn.tree import DecisionTreeClassifier
dtc = DecisionTreeClassifier()
dtc.fit(X_train, y_train)
dtc_y_pred = dtc.predict(X_test)
```


```python
# 使用个随机森林分类器进行集成模型的训练以及预测分析
from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier()
rfc.fit(X_train, y_train)
rfc_y_pred = rfc.predict(X_test)
```


```python
# 使用梯度提升决策树进行集成模型的训练以及预测分析
from sklearn.ensemble import GradientBoostingClassifier
gbc = GradientBoostingClassifier()
gbc.fit(X_train, y_train)
gbc_y_pred = gbc.predict(X_test)
```

### 代码33：集成模型预测性能


```python
from sklearn.metrics import classification_report
# 输出单一决策树在测试集上的分类准确性，以及更加详细的精确率、召回率、F1指标
print("The Accuracy of decision tree is:", dtc.score(X_test, y_test))
print(classification_report(dtc_y_pred, y_test))
```

    The Accuracy dof decision tree is: 0.7811550151975684
                 precision    recall  f1-score   support
    
              0       0.91      0.78      0.84       236
              1       0.58      0.80      0.67        93
    
    avg / total       0.81      0.78      0.79       329
    
    


```python
# 输出随机森林在测试集上的分类准确性，以及更加详细的精确率、召回率、F1指标
print("The Accuracy of RandomForest is:", rfc.score(X_test, y_test))
print(classification_report(rfc_y_pred, y_test))
```

    The Accuracy of RandomForest is: 0.7872340425531915
                 precision    recall  f1-score   support
    
              0       0.91      0.78      0.84       236
              1       0.59      0.81      0.68        93
    
    avg / total       0.82      0.79      0.80       329
    
    


```python
# 输出梯度提升决策树在测试集上的分类准确性，以及更加详细的精确率、召回率、F1指标
print("The Accuracy of Gradient tree boosting is:", gbc.score(X_test, y_test))
print(classification_report(gbc_y_pred, y_test))
```

    The Accuracy of Gradient tree boosting is: 0.790273556231003
                 precision    recall  f1-score   support
    
              0       0.92      0.78      0.84       239
              1       0.58      0.82      0.68        90
    
    avg / total       0.83      0.79      0.80       329
    
    

***结果表明，在相同的训练和测试数据条件下，仅仅使用模型的默认配置，梯度上升决策树具有最佳的预测性能，其次是随机森林分类器，最后是单一决策树。大量在其他数据上的模型实践也证明了上述结论的普适性。一般而言，工业界为了追求更加强劲的预测性能，经常使用随机森林分类模型作为基线系统***

***集成模型可以说是实战应用中最为常见的。相比于其他单一的学习模型，集成模型可以整合多种模型，或者多次就一种类型的模型进行建模。由于模型估计参数的过程也同样收到概率的影响，具有一定的不确定性；因此，集成模型虽然在训练过程中要耗费更多的时间，但是得到的集成模型往往具有更高的表现性能和更好的稳定性。***

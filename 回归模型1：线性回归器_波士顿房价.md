
***回归问题和分类问题的区别在于，其待预测的目标是连续变量，比如：价格、降水量、体重、体积等。只用波士顿房价的数据对各种回归模型的性能和优缺点做一个深入的比较。***

***和线性分类器不同，线性分类器为了便于将原本在实数域上的计算结果映射到（0,1）区间，引入了逻辑斯谛函数。而且线性回归问题中，由于预测目标直接是实数域上的数值，因此优化目标就更为简单，即最小化预测结果与真实值之间的差异。（损失函数最小化）***

***线性回归模型可以最小二乘预测的损失L(w, b),为了学习到决定模型的参数，即系数w和截距b，仍然可以使用一种精确计算的解析方法和一种快速的随机梯度下降估计算法。***   
***小贴士***事实上，不管是随机梯度上升（SGA）还是随机梯度下降（SGD），都隶属于用梯度法迭代渐进估计参数的过程。梯度上升用于目标最大化，梯度下降用于目标最小化。在线性回归中，我们使用优化目标最小化的方程。

### 代码34：美国波士顿地区房价数据描述


```python
from sklearn.datasets import load_boston
boston = load_boston()
print(boston.DESCR)
```

    Boston House Prices dataset
    ===========================
    
    Notes
    ------
    Data Set Characteristics:  
    
        :Number of Instances: 506 
    
        :Number of Attributes: 13 numeric/categorical predictive
        
        :Median Value (attribute 14) is usually the target
    
        :Attribute Information (in order):
            - CRIM     per capita crime rate by town
            - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.
            - INDUS    proportion of non-retail business acres per town
            - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)
            - NOX      nitric oxides concentration (parts per 10 million)
            - RM       average number of rooms per dwelling
            - AGE      proportion of owner-occupied units built prior to 1940
            - DIS      weighted distances to five Boston employment centres
            - RAD      index of accessibility to radial highways
            - TAX      full-value property-tax rate per $10,000
            - PTRATIO  pupil-teacher ratio by town
            - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town
            - LSTAT    % lower status of the population
            - MEDV     Median value of owner-occupied homes in $1000's
    
        :Missing Attribute Values: None
    
        :Creator: Harrison, D. and Rubinfeld, D.L.
    
    This is a copy of UCI ML housing dataset.
    http://archive.ics.uci.edu/ml/datasets/Housing
    
    
    This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.
    
    The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic
    prices and the demand for clean air', J. Environ. Economics & Management,
    vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics
    ...', Wiley, 1980.   N.B. Various transformations are used in the table on
    pages 244-261 of the latter.
    
    The Boston house-price data has been used in many machine learning papers that address regression
    problems.   
         
    **References**
    
       - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.
       - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.
       - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)
    
    

### 代码35：美国波士顿地区房价数据分割


```python
from sklearn.cross_validation import train_test_split
import numpy as np
X = boston.data
y = boston.target
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state =33, test_size = 0.25)
# 分析回归目标值的差异
print("The max target value is:", np.max(y))
print("The min target value is:", np.min(y))
print("The average target value is:", np.mean(y))
```

    The max target value is: 50.0
    The min target value is: 5.0
    The average target value is: 22.532806324110677
    

在对数据的初步查验中发现，预测目标房价之间的差异较大，因此需要对特征以及目标值进行标准化处理。事实上，尽管在标准化之后，数据有了很大的变化，但是我们依然可以使用标准化器中的inverse_transform函数还原真实的结果；并且，对于预测的回归值也可以采用相同的做法进行还原。

### 代码36：训练与测试数据标准化处理


```python
from sklearn.preprocessing import StandardScaler
# 分别初始化对特征和目标值的标准化器
ss_X = StandardScaler() 
ss_y = StandardScaler()
# 分别对训练和测试数据的特征以及目标值进行标准化处理
X_train = ss_X.fit_transform(X_train)
X_test = ss_X.transform(X_test)
y_train = ss_y.fit_transform(y_train.reshape(-1,1))
y_test = ss_y.transform(y_test.reshape(-1,1))
```

### 代码37：使用线性回归模型LinearRegression和SGDRegressor分别对美国波士顿地区房价进行预测


```python
from sklearn.linear_model import LinearRegression
lr = LinearRegression()
lr.fit(X_train, y_train)
lr_y_predict = lr.predict(X_test)
```


```python
from sklearn.linear_model import SGDRegressor
sgdr = SGDRegressor()
sgdr.fit(X_train, y_train)
sgdr_y_predict = sgdr.predict(X_test)
```

    C:\ProgramData\Anaconda3\lib\site-packages\sklearn\linear_model\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
      "and default tol will be 1e-3." % type(self), FutureWarning)
    C:\ProgramData\Anaconda3\lib\site-packages\sklearn\utils\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
      y = column_or_1d(y, warn=True)
    

### 代码38：使用三种回归评价机制以及两种调用R-squared评价模块的方法，对模型的回归性能进行评价

***我们可以通过多种测评函数对预测结果进行评价，其中最为直观的评价指标包括，平均绝对误差（MAE）以及均方误差（MSE）,但是差值的绝对值或者是平方值都会随着不同的预测问题而变化巨大，欠缺在不同问题中的可比性。而R-squared用来衡量回归结果的波动可被真实值验证的百分比，也暗示了模型在数值回归方面的能力。***


```python
# 使用LR模型自带的评估模块，并输出评估结果
print("The value of default masurement of LR is :" ,lr.score(X_test, y_test))
# 从sklearn.metrics导入r2_score\mean_squared_error和mean_absolute_error用于回归性能的评估
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
print("The value of R-squared of LR is:", r2_score(y_test, lr_y_predict))
print("The mean squared error of LR is:", mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(lr_y_predict)))
print("The mean absoluate error of LR is:", mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(lr_y_predict)))
```

    The value of default masurement of LR is : 0.6763403830998702
    The value of R-squared of LR is: 0.6763403830998702
    The mean squared error of LR is: 25.096985692067722
    The mean absoluate error of LR is: 3.526123996398543
    


```python
print("The value of default measurement of SGDR is:", sgdr.score(X_test, y_test))
print("The R2 score of SGDR is:", r2_score(y_test, sgdr_y_predict))
print("The mean squared error of SGDR is:", mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(sgdr_y_predict)))
print("The mean absolute error of SGDR is:", mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(sgdr_y_predict)))
```

    The value of default measurement of SGDR is: 0.6585298686378961
    The R2 score of SGDR is: 0.6585298686378962
    The mean squared error of SGDR is: 26.47803604027491
    The mean absolute error of SGDR is: 3.533273444261717
    

***虽然使用随机梯度下降估计参数的方法在性能表现上不及使用解析方法的linearRegression，但是如果面对训练数据规模十分庞大的任务，随机梯度法不论是在分类还是回归问题上都表现的十分高效，可以在不损失过多性能的前提下，节省大量计算时间。如果数据规模超10万，推荐使用随机梯度法估计参数模型***

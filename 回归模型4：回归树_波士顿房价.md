
***回归树在选择不同特征作为分裂节点的策略上，与决策树思路类似。不同之处在于，回归树叶节点的数据类型不是离散型，而是连续型。决策树每个叶节点依照训练数据表现的概率倾向决定了其最终的预测类别，而回归树的叶节点却是一个个具体的值，从预测值连续这个意义上严格来讲，回归树不能称为‘回归算法’。因为回归树的叶节点返回的是“一团”训练数据均值，而不是具体的、连续的预测值。***


```python
from sklearn.datasets import load_boston
boston = load_boston()
from sklearn.cross_validation import train_test_split
import numpy as np
X = boston.data
y = boston.target
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state =33, test_size = 0.25)
from sklearn.preprocessing import StandardScaler
# 分别初始化对特征和目标值的标准化器
ss_X = StandardScaler() 
ss_y = StandardScaler()
# 分别对训练和测试数据的特征以及目标值进行标准化处理
X_train = ss_X.fit_transform(X_train)
X_test = ss_X.transform(X_test)
y_train = ss_y.fit_transform(y_train.reshape(-1,1))
y_test = ss_y.transform(y_test.reshape(-1,1))
```

    C:\ProgramData\Anaconda3\lib\site-packages\sklearn\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
      "This module will be removed in 0.20.", DeprecationWarning)
    

### 代码43：使用回归树对美国波士顿房价训练数据进行学习，并对测试数据进行预测


```python
from sklearn.tree import DecisionTreeRegressor
dtr = DecisionTreeRegressor()
dtr.fit(X_train, y_train)
dtr_y_pre = dtr.predict(X_test)
```

### 代码44：对单一回归树模型在美国波士顿房价测试数据上的预测性能进行评估


```python
from sklearn.metrics import mean_squared_error, mean_absolute_error
print("回归树R2值：", dtr.score(X_test, y_test))
print("回归树MSE值：", mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(dtr_y_pre)))
print("回归树MAE值：", mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(dtr_y_pre)))
```

    回归树R2值： 0.6538100646957374
    回归树MSE值： 26.8440157480315
    回归树MAE值： 3.1976377952755906
    

***我们发现回归树的结果优于线性回归器的性能表现。因此可以初步判断“美国波士顿房价预测”问题的特征与目标值之间存在一定的非线性关系。  
在系统地介绍了决策（分类）树和回归树之后，可以总结这类树模型的优点：  ***
1. 树模型可以解决非线性特征的问题；
2. 树模型不要求对特征标准化和统一量化，即数值型和类别型特征都可以直接被应用在树模型的构建和预测过程中；  
3. 因为上述原因，树模型也可以直观地输出决策过程，是的预测结果具有可解释性。  
***同时，树模型也有一些显著的缺陷：***  
1. 正是因为树模型可以解决复杂的非线性拟合问题，所以更加容易因为模型搭建过于复杂而丧失对新数据预测的精度（泛化力）；  
2. 树模型从上至下的预测流程会因为数据细微的更改而发生较大的结构变化，因此预测稳定性较差；  
3. 依托训练数据构建最佳的树模型是NP难问题，即在有限时间内无法找到最优解的问题，因此我们所使用类似贪心算法的解法只能找到一些次优解，这也是我们为什么经常借助集成模型，在多个次优解中寻觅更高的模型性能。  
